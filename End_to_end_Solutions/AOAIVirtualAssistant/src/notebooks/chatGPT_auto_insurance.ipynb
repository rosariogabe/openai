{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0272de7-83b7-4c9c-9913-1ede21c55cc2",
   "metadata": {},
   "source": [
    "# Building an auto insurance chatbot using Azure OpenAI ChatGPT\n",
    "\n",
    "### Problem description\n",
    "    Build an Auto insurance chatbot to help users by answering their questions about auto insurance plans and providing personalized recommendations based on the user account information.\n",
    "\n",
    "    Within the chatbot workflow, this model is placed after the topic classifier (which distinguishes the topic of a user input), and is only responsible for handling user utterances that are relevant to auto insurance questions.\n",
    "### Background\n",
    "    The chatbot is for an insurance company called Contoso, Ltd.\n",
    "    The chatbot has access to relevant FAQ knowledge base on auto insurance, as well as customers information.\n",
    "    \n",
    "    An example on customer information shown below:\n",
    "        Insurer's Name: Dave Huang\n",
    "        Membership Start Date: March 2019\n",
    "        Auto Insurance: Yes\n",
    "        Auto Insurance Deductible: $500 per incident\n",
    "        Auto Insurance Claims history: auto accident in Jan 2020; auto accident in Apr 2022 \n",
    "        Safe Driver Rating: 22 of 100\n",
    "        Home Insurance: No\n",
    "        Flood Insurance: No\n",
    "        Home Address: 100 Main Street, Seattle, WA\n",
    "        Flood Risk Factor: 8 of 10\n",
    "        Bundling Discount: No\n",
    "        Safe Driver Discount: No\n",
    "            \n",
    "### Approach\n",
    "    The model is built using Azure OpenAI ChatGPT-turbo base model, relevant information (insurance knowledge and user account information) is provided in the system prompt.\n",
    "\n",
    "### Result\n",
    "    The chatbot is working as expected, it can provide personalized answers based on knowledge base and user account information. A few manual evaluation examples on two user accounts are included.\n",
    "\n",
    "**note**: This notebook is built using the March 2023 version of ChatGPT (gpt-35-turbo). As ChatGPT version is updated roughly once a month, please re-evaluate your prompt engineering if you are using a version that is more recent than March 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad26e4d-8683-4160-a34b-5c5db894e04d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ad5dd2-13bd-484b-9d71-81cdc6c95d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pelase make sure to install required libraries: pip install -r requirements.txt\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"    \n",
    "openai.api_key = os.getenv('6d6be8b9e8c64360b2e45f5c2ffe4d0a')\n",
    "openai.api_base = \"https://innova-openai.openai.azure.com/\"\n",
    "openai.api_version = \"max-insurance\"\n",
    "\n",
    "#ChatGPT deployment name\n",
    "chatgpt_model_name = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a736bd-18e0-466f-88dd-d8f8b62eb64b",
   "metadata": {},
   "source": [
    "# prompt engineering + API calls\n",
    "\n",
    "All chat history relevant to the topic of auto insurance is combined for ChatGPT to \"remember\" and be aware of the dialogue state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907ec82a-8925-4cc1-9ff0-c1a653f28453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_user_prompt(user_input):\n",
    "    '''Return prompt\n",
    "    add ChatGPT prompt format before and after each user_input\n",
    "    \n",
    "    this format can change in the future, please refer to Azure OpenAI page for latest guidance\n",
    "    '''\n",
    "    prompt_input = f\"\\n<|im_end|>\\n<|im_start|>user\\n{user_input}\\n<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    return prompt_input\n",
    "\n",
    "def engineer_prompt(user_input, lst_user_bot_input):\n",
    "    '''\n",
    "    prompt engineering so the bot has context of previous conversations\n",
    "    \n",
    "    continue appending previous conversations so the lateste prompt include all previous chat history\n",
    "    '''\n",
    "    prompt_eng = engineer_user_prompt(user_input)\n",
    "    lst_user_bot_input.append(prompt_eng)\n",
    "    prompt_input = ''.join(lst_user_bot_input)\n",
    "    \n",
    "    return prompt_input\n",
    "\n",
    "def call_chatgpt(prompt_input, deployment_name=chatgpt_model_name):\n",
    "    '''\n",
    "    call ChatGPT API, and set parameters, return useful output from API call\n",
    "    '''\n",
    "    response = openai.Completion.create(\n",
    "        engine=deployment_name,\n",
    "        prompt = prompt_input,\n",
    "        temperature = 0,\n",
    "        max_tokens = 500,\n",
    "        frequency_penalty = 0.5,\n",
    "        presence_penalty = 0.0,\n",
    "        stop=['<|im_end|>'],\n",
    "      )\n",
    "    \n",
    "    return response[\"choices\"][0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f47fc946-579a-4ac5-879d-542f7797303d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_dave = \"\"\"\n",
    "        Insurer's Name: Dave Huang\n",
    "        Membership Start Date: March 2019\n",
    "        Auto Insurance: Yes\n",
    "        Auto Insurance Deductible: $500 per incident\n",
    "        Auto Insurance Claims history: auto accident in Jan 2020; auto accident in Apr 2022 \n",
    "        Safe Driver Rating: 22 of 100\n",
    "        Home Insurance: No\n",
    "        Flood Insurance: No\n",
    "        Home Address: 100 Main Street, Seattle, WA\n",
    "        Flood Risk Factor: 8 of 10\n",
    "        Bundling Discount: No\n",
    "        Safe Driver Discount: No\n",
    "        Driving Habit Tracking Device Discount: No\n",
    "        \"\"\"\n",
    "user_emma = \"\"\"\n",
    "        Insurer's Name: Emma Miller\n",
    "        Membership Start Date: December 2017\n",
    "        Auto Insurance: Yes\n",
    "        Auto Insurance Deductible: $500 per incident\n",
    "        Auto Insurance Claims history: None\n",
    "        Safe Driver Rating: 90 of 100\n",
    "        Home Insurance: Yes\n",
    "        Home Flood Insurance: No\n",
    "        Home Address: 44, 170th Ave, Redmond, WA\n",
    "        Flood Risk Factor: 1 of 10\n",
    "        Bundling Discount: Yes\n",
    "        Safe Driver Discount: Yes\n",
    "        Driving Habit Tracking Device Discount: No\n",
    "        \"\"\"\n",
    "lst_users = [user_dave, user_emma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7707a9d-9ced-4ada-890f-2e08ed913c72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_system_prompt(user):\n",
    "    '''\n",
    "    build system prompt, add relevant information into it\n",
    "    '''\n",
    "    \n",
    "    prompt_system = f\"\"\"<|im_start|>system  \n",
    "    As an auto insurance agent at Contoso, Assistant's role is to help users by answering their questions about auto insurance plans and providing personalized recommendations based on the User Account Information (Content A). \n",
    "    Assistant should never refer the user to any other insurance companies, repeat previously stated sentences or information, or provide quotes. \n",
    "    Assistant is a passive advisor; Assistant doesn't ask user questions.\n",
    "    \n",
    "    Content A: User Account Information  \n",
    "        {user}\n",
    "\n",
    "    Content B. Ways to Lower Insurance Premium:  \n",
    "        1. Bundling Discount. Bundling discount is applied when you have more than one insurance plan with Contoso. Prioritize recommend bundling if the user's Bundling Discount is No.\n",
    "        2. Increase Deductible. The higher your deductible, the lower your premium will be. $500 is the average.\n",
    "        3. Safe Driver Discount. Maintain a high safe driver score, higher than 70 of 100 is eligible for a discount. The higher rating you have, the lower your premium will be. \n",
    "        4. Driving Habit Tracking Device Discount. Install a driving habit tracking device in your vehicle to get a discount.\n",
    "    \n",
    "    If a user wants to get a quote or asks about cost of premium, Assistant should reply and only reply with \"Let me connect you with a quote specialist at Contoso who can then help you further. Please hold while I connect you.\" and say nothing else.\n",
    "    Assistant has access to all Account Information for the user from Content A. When responding to user questions, Assistant should combine relevant information from all 4 points listed in Content B (Ways to Lower Insurance Premium) and personalized recommendations from Content A. \n",
    "    Assistant should always go through all 4 points one by one in Ways to Lower Insurance Premium (Content B) and determine if it applies to the user based on User Account Information (Content A). If the point does not apply, explain what the user needs to do in order to qualify. Prioritize recommend bundling if the user currently don't have Bundling Discount.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c5aa90-4efc-44ac-bf3d-10f548f7ff05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_lst_questions(user):\n",
    "    '''\n",
    "    put together system prompt and pre-programmed user questions input in sequence\n",
    "    '''\n",
    "    lst_user_bot_input = [engineer_system_prompt(user)]\n",
    "\n",
    "    user_input_1 = \"\"\"What are some ways for me to lower my insurance premium?\"\"\"\n",
    "    user_input_2 = \"\"\"Can you tell me more about bundling?\"\"\"\n",
    "    user_input_3 = \"\"\"Thank you for the detailed explanation. I would like to get a quote with bundling auto and home insurance\"\"\" \n",
    "\n",
    "    lst_user_inputs = [user_input_1, user_input_2, user_input_3]\n",
    "\n",
    "    return lst_user_bot_input, lst_user_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b792ddcd-64cd-4dd5-9e5e-081d52221462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_conversation(user, tag_display_code=False):\n",
    "    '''\n",
    "    call ChatGPT API and display User questions and ChatGPT replies in conversational style\n",
    "    making it easier to evaluate the results\n",
    "    '''\n",
    "    lst_user_bot_input, lst_user_inputs = engineer_lst_questions(user)\n",
    "    for i, user_input_i in enumerate(lst_user_inputs):\n",
    "        prompt_input_i = engineer_prompt(user_input_i, lst_user_bot_input)\n",
    "        response_i = call_chatgpt(prompt_input_i)\n",
    "        lst_user_bot_input.append(response_i)\n",
    "        # display output along each round of conversation\n",
    "        print(f\"{user_input_i}\\n---------------\\n{response_i}\\n---------------\")\n",
    "        \n",
    "    if tag_display_code: #display all prompt (code style)\n",
    "        print(f\"\\n==============================\\nCode style Prompt and Responses\\n==============================\\n{prompt_input_i}{response_i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8bb0c0d-500e-4b8d-a602-97866eb4c881",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m call_chatgpt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m, in \u001b[0;36mcall_chatgpt\u001b[0;34m(prompt_input, deployment_name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_chatgpt\u001b[39m(prompt_input, deployment_name\u001b[38;5;241m=\u001b[39mchatgpt_model_name):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    call ChatGPT API, and set parameters, return useful output from API call\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     27\u001b[0m         engine\u001b[38;5;241m=\u001b[39mdeployment_name,\n\u001b[1;32m     28\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m prompt_input,\n\u001b[1;32m     29\u001b[0m         temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     30\u001b[0m         max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     31\u001b[0m         frequency_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     32\u001b[0m         presence_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     33\u001b[0m         stop\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<|im_end|>\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     34\u001b[0m       )\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "response = call_chatgpt(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecd7b1-bc8b-40e4-8ab7-8a47d6e830d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
